###Source: https://towardsdatascience.com/time-series-of-price-anomaly-detection-with-lstm-11a12ba4f6d9

# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hLA-ShH0NDZUIg6Is9n8Goye8sv4Whvg
"""



"""Source: https://towardsdatascience.com/time-series-of-price-anomaly-detection-with-lstm-11a12ba4f6d9"""

import pandas as pd
import numpy as np
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed


"""Get Data:"""

df_average = pd.read_csv('Average_DATA_IBM_2020-06-05-00-00-00_to_2020-10-18-16-25-33.csv', parse_dates=True, index_col=0)
df_average.index = pd.to_datetime(df_average.index, yearfirst=True)
print(df_average)

"""Visualize Data"""

fig = px.line(df_average, x=df_average.index, y=df_average.average, title='Average Sensor Temperature')
fig.show()

"""Creating and transforming train and test data"""

split = int(0.8 * len(df_average))
train, test = df_average[:split], df_average[split:]
print(train.shape, test.shape)


scaler = StandardScaler()
scaler = scaler.fit(train[['average']])

train['average'] = scaler.transform(train[['average']])
test['average'] = scaler.transform(test[['average']])


TIME_STEPS=10

def create_sequences(X, y, time_steps=TIME_STEPS):
    Xs, ys = [], []
    for i in range(len(X)-time_steps):
        Xs.append(X.iloc[i:(i+time_steps)].values)
        ys.append(y.iloc[i+time_steps])

    return np.array(Xs), np.array(ys)

X_train, y_train = create_sequences(train[['average']], train['average'])
X_test, y_test = create_sequences(test[['average']], test['average'])

print(f'Training shape: {X_train.shape}')
print(f'Testing shape: {X_test.shape}')

"""Build Model"""

model = Sequential()
model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(rate=0.2))
model.add(RepeatVector(X_train.shape[1]))
model.add(LSTM(128, return_sequences=True))
model.add(Dropout(rate=0.2))
model.add(TimeDistributed(Dense(X_train.shape[2])))
model.compile(optimizer='adam', loss='mae')
model.summary()

"""Train the Model"""

history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1,
                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')], shuffle=False)


plt.plot(history.history['loss'], label='Training loss')
plt.plot(history.history['val_loss'], label='Validation loss')
plt.legend()
plt.show()

model.evaluate(X_test, y_test)


"""Determine Anomalies"""

X_train_pred = model.predict(X_train, verbose=0)
train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=1)

plt.hist(train_mae_loss, bins=50)
plt.xlabel('Train MAE loss')
plt.ylabel('Number of Samples')
plt.show()

# threshold = np.max(train_mae_loss)
threshold = 0.6
print(f'Reconstruction error threshold: {threshold}')


X_test_pred = model.predict(X_test, verbose=0)
test_mae_loss = np.mean(np.abs(X_test_pred-X_test), axis=1)

plt.hist(test_mae_loss, bins=50)
plt.xlabel('Test MAE loss')
plt.ylabel('Number of samples')
plt.show()


test_score_df = pd.DataFrame(test[TIME_STEPS:])
test_score_df['loss'] = test_mae_loss
test_score_df['threshold'] = threshold
test_score_df['anomaly'] = test_score_df['loss'] > test_score_df['threshold']
test_score_df['average'] = test[TIME_STEPS:]['average']

fig = go.Figure()
fig.add_trace(go.Scatter(x=test_score_df.index, y=test_score_df['loss'], name='Test loss'))
fig.add_trace(go.Scatter(x=test_score_df.index, y=test_score_df['threshold'], name='Threshold'))
fig.update_layout(showlegend=True, title='Test loss vs. Threshold')
fig.show()


anomalies = test_score_df.loc[test_score_df['anomaly'] == True]
anomalies.shape


fig = go.Figure()
fig.add_trace(go.Scatter(x=test_score_df.index, y=scaler.inverse_transform(test_score_df['average']), name='Average Temperature'))
fig.add_trace(go.Scatter(x=anomalies.index, y=scaler.inverse_transform(anomalies['average']), mode='markers', name='Anomaly'))
fig.update_layout(showlegend=True, title='Detected anomalies')
fig.show()